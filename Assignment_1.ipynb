{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Assignment 1 - Food Classification Model (Individual)</h2><h3>AY2020/21 Semester</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras:  2.2.4-tf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the Required Packages\n",
    "\n",
    "from tensorflow import keras\n",
    "print('keras: ', keras.__version__)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Set the base directory as the current directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "#Set the base directory as where you save the downloaded food_images\n",
    "image_dir = 'C:/Poly/Year 2/Year 2 sem 1/DL/Assignment/food-101/food-101/food-101/images' \n",
    "\n",
    "# Directories for your training, validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# Assign the 10 types of food from your .txt file to a list variable 'food_list'\n",
    "   \n",
    "label_file = os.path.join(base_dir, '25.txt') \n",
    "# Refer to the report Appendix\n",
    "# Please enter the name of .txt file which contains a list of food assigned to you\n",
    "# Make sure you save the .txt file in your base_dir\n",
    "\n",
    "with open(label_file, 'r') as f:\n",
    "    x = f.readlines()\n",
    "    \n",
    "food_list =[]\n",
    "for item in x:\n",
    "    if item == '\\n':\n",
    "        continue        \n",
    "    else:\n",
    "        food_list.append(item.strip('\\n'))\n",
    "        \n",
    "#copy the first 750 images to train folder\n",
    "for item in food_list:\n",
    "    train_food_dir = os.path.join(train_dir, item)\n",
    "    os.mkdir(train_food_dir)\n",
    "    img_list = os.listdir(os.path.join(image_dir, item))[:750]\n",
    "    for fname in img_list:\n",
    "        src = os.path.join(image_dir, item, fname)\n",
    "        dst = os.path.join(train_food_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "#copy the following 200 images [750:950] to validation folder\n",
    "for item in food_list:\n",
    "    validation_food_dir = os.path.join(validation_dir, item)\n",
    "    os.mkdir(validation_food_dir)\n",
    "    img_list = os.listdir(os.path.join(image_dir, item))[750:950]\n",
    "    for fname in img_list:\n",
    "        src = os.path.join(image_dir, item, fname)\n",
    "        dst = os.path.join(validation_food_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "#copy the remaining 50 images [950:1000] to test folder\n",
    "for item in food_list:\n",
    "    test_food_dir = os.path.join(test_dir, item)\n",
    "    os.mkdir(test_food_dir)\n",
    "    img_list = os.listdir(os.path.join(image_dir, item))[950:1000]\n",
    "    for fname in img_list:\n",
    "        src = os.path.join(image_dir, item, fname)\n",
    "        dst = os.path.join(test_food_dir, fname)\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Develop the Image Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 312,010\n",
      "Trainable params: 312,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 7500 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Build the Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "#Set image size as 150*150.\n",
    "img_size = 50\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(img_size, img_size, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255)\n",
    "#      rotation_range=40,\n",
    "#      width_shift_range=0.2,\n",
    "#      height_shift_range=0.2,\n",
    "#      shear_range=0.2,\n",
    "#      zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 50x50\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=50,\n",
    "        class_mode='categorical')\n",
    "\n",
    "#test_generator = test_datagen.flow_from_directory(\n",
    "#        test_food_dir,\n",
    "#        target_size=(img_size, img_size),\n",
    "#        batch_size=10,\n",
    "#        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 150 steps, validate for 100 steps\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - 103s 686ms/step - loss: 2.1652 - acc: 0.2083 - val_loss: 1.9008 - val_acc: 0.3240\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - 97s 647ms/step - loss: 1.9216 - acc: 0.3267 - val_loss: 1.7711 - val_acc: 0.3845\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 97s 645ms/step - loss: 1.7964 - acc: 0.3796 - val_loss: 1.7607 - val_acc: 0.4015\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 101s 672ms/step - loss: 1.6898 - acc: 0.4223 - val_loss: 1.6919 - val_acc: 0.4290\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 103s 689ms/step - loss: 1.5822 - acc: 0.4643 - val_loss: 1.6785 - val_acc: 0.4245\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 103s 688ms/step - loss: 1.4811 - acc: 0.4977 - val_loss: 1.4606 - val_acc: 0.5035\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 108s 722ms/step - loss: 1.3822 - acc: 0.5359 - val_loss: 1.4225 - val_acc: 0.5235\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 107s 715ms/step - loss: 1.2926 - acc: 0.5641 - val_loss: 1.4235 - val_acc: 0.5215\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 103s 684ms/step - loss: 1.1918 - acc: 0.5968 - val_loss: 1.3823 - val_acc: 0.5440\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 101s 671ms/step - loss: 1.1006 - acc: 0.6303 - val_loss: 1.3971 - val_acc: 0.5335\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 97s 644ms/step - loss: 1.0119 - acc: 0.6591 - val_loss: 1.4509 - val_acc: 0.5440\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 101s 674ms/step - loss: 0.9139 - acc: 0.6899 - val_loss: 1.5618 - val_acc: 0.5235\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 104s 692ms/step - loss: 0.8178 - acc: 0.7208 - val_loss: 1.5263 - val_acc: 0.5540\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 86s 576ms/step - loss: 0.7217 - acc: 0.7499 - val_loss: 1.5822 - val_acc: 0.5460\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 73s 483ms/step - loss: 0.6389 - acc: 0.7859 - val_loss: 1.6018 - val_acc: 0.5745\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - 75s 502ms/step - loss: 0.5370 - acc: 0.8184 - val_loss: 1.6868 - val_acc: 0.5495\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - 75s 500ms/step - loss: 0.4583 - acc: 0.8443 - val_loss: 1.8871 - val_acc: 0.5310\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - 73s 488ms/step - loss: 0.3979 - acc: 0.8684 - val_loss: 1.9514 - val_acc: 0.5580\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - 77s 512ms/step - loss: 0.3482 - acc: 0.8841 - val_loss: 2.1567 - val_acc: 0.5325\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - 75s 499ms/step - loss: 0.2987 - acc: 0.8992 - val_loss: 2.2800 - val_acc: 0.5535\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - 81s 540ms/step - loss: 0.2439 - acc: 0.9201 - val_loss: 2.5468 - val_acc: 0.5295\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - 78s 517ms/step - loss: 0.2359 - acc: 0.9195 - val_loss: 2.6859 - val_acc: 0.5300\n",
      "Epoch 23/30\n",
      "150/150 [==============================] - 88s 586ms/step - loss: 0.1935 - acc: 0.9351 - val_loss: 2.7086 - val_acc: 0.5480\n",
      "Epoch 24/30\n",
      "150/150 [==============================] - 93s 619ms/step - loss: 0.1748 - acc: 0.9413 - val_loss: 2.7565 - val_acc: 0.5400\n",
      "Epoch 25/30\n",
      "150/150 [==============================] - 96s 642ms/step - loss: 0.1671 - acc: 0.9435 - val_loss: 3.0703 - val_acc: 0.5305\n",
      "Epoch 26/30\n",
      "150/150 [==============================] - 90s 599ms/step - loss: 0.1580 - acc: 0.9496 - val_loss: 3.1312 - val_acc: 0.5420\n",
      "Epoch 27/30\n",
      "140/150 [===========================>..] - ETA: 5s - loss: 0.1367 - acc: 0.9563"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-59775ad27c28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m       validation_steps=100) # 10 * 20 = 200 = 200 validation images\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=150, # batch: 10 * 75 = 750 training images\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=100) # 10 * 20 = 200 = 200 validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Training and Validation Accuracy & Loss Scores\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "model.save('food_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 16,814,666\n",
      "Trainable params: 2,099,978\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Found 7500 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "img_size = 150\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(img_size, img_size, 3))\n",
    "\n",
    "conv_base.trainable = False\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base) #ResNet50 pretrained\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "conv_base.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "#test_generator = test_datagen.flow_from_directory(\n",
    "#        test_food_dir,\n",
    "#        target_size=(img_size, img_size),\n",
    "#        batch_size=10,\n",
    "#        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 375 steps, validate for 100 steps\n",
      "Epoch 1/30\n",
      "375/375 [==============================] - 2678s 7s/step - loss: 1.9535 - acc: 0.3267 - val_loss: 1.6138 - val_acc: 0.4845\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 2472s 7s/step - loss: 1.5798 - acc: 0.4767 - val_loss: 1.3715 - val_acc: 0.5500\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 3865s 10s/step - loss: 1.4242 - acc: 0.5296 - val_loss: 1.2750 - val_acc: 0.5845\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 3534s 9s/step - loss: 1.3446 - acc: 0.5555 - val_loss: 1.1958 - val_acc: 0.6020\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 2170s 6s/step - loss: 1.2859 - acc: 0.5737 - val_loss: 1.1437 - val_acc: 0.6235\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 2267s 6s/step - loss: 1.2353 - acc: 0.5928 - val_loss: 1.1097 - val_acc: 0.6355\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 8097s 22s/step - loss: 1.1994 - acc: 0.6019 - val_loss: 1.0807 - val_acc: 0.6500\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 4768s 13s/step - loss: 1.1819 - acc: 0.6015 - val_loss: 1.0465 - val_acc: 0.6580\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 3910s 10s/step - loss: 1.1600 - acc: 0.6127 - val_loss: 1.0544 - val_acc: 0.6435\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 35364s 94s/step - loss: 1.1357 - acc: 0.6192 - val_loss: 1.0218 - val_acc: 0.6600\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 5539s 15s/step - loss: 1.1238 - acc: 0.6265 - val_loss: 0.9927 - val_acc: 0.6690\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 3111s 8s/step - loss: 1.1065 - acc: 0.6343 - val_loss: 1.0054 - val_acc: 0.6635\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 3255s 9s/step - loss: 1.1049 - acc: 0.6368 - val_loss: 0.9847 - val_acc: 0.6735\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 3144s 8s/step - loss: 1.0812 - acc: 0.6375 - val_loss: 0.9923 - val_acc: 0.6725\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 2369s 6s/step - loss: 1.0678 - acc: 0.6441 - val_loss: 0.9661 - val_acc: 0.6730\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 2714s 7s/step - loss: 1.0573 - acc: 0.6493 - val_loss: 0.9569 - val_acc: 0.6840\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 3067s 8s/step - loss: 1.0443 - acc: 0.6513 - val_loss: 0.9737 - val_acc: 0.6745\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 3249s 9s/step - loss: 1.0413 - acc: 0.6508 - val_loss: 0.9393 - val_acc: 0.6900\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 2720s 7s/step - loss: 1.0281 - acc: 0.6619 - val_loss: 0.9475 - val_acc: 0.6870\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 2527s 7s/step - loss: 1.0277 - acc: 0.6625 - val_loss: 0.9438 - val_acc: 0.6820\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 2563s 7s/step - loss: 1.0062 - acc: 0.6629 - val_loss: 0.9364 - val_acc: 0.6910\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 2517s 7s/step - loss: 1.0124 - acc: 0.6639 - val_loss: 0.9374 - val_acc: 0.6870\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 2715s 7s/step - loss: 1.0034 - acc: 0.6652 - val_loss: 0.9466 - val_acc: 0.6875\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 25979s 69s/step - loss: 0.9944 - acc: 0.6731 - val_loss: 0.9325 - val_acc: 0.6840\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 2629s 7s/step - loss: 0.9871 - acc: 0.6685 - val_loss: 0.9183 - val_acc: 0.6920\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 2985s 8s/step - loss: 0.9944 - acc: 0.6683 - val_loss: 0.9336 - val_acc: 0.6840\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 2974s 8s/step - loss: 0.9870 - acc: 0.6687 - val_loss: 0.9176 - val_acc: 0.6895\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 2908s 8s/step - loss: 0.9798 - acc: 0.6777 - val_loss: 0.9252 - val_acc: 0.6850\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 2861s 8s/step - loss: 0.9686 - acc: 0.6741 - val_loss: 0.9068 - val_acc: 0.6985\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 2855s 8s/step - loss: 0.9755 - acc: 0.6789 - val_loss: 0.9102 - val_acc: 0.6955\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=375, # batch: 10 * 75 = 750 training images\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=100) # 10 * 20 = 200 = 200 validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Training and Validation Accuracy & Loss Scores\n",
    "# Plot the Training and Validation Accuracy & Loss Scores\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "model.save('food_model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3  Evaluate the Developed Models using Testing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #1\n",
    "model.load_weights('food_model_1.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #2\n",
    "model.load_weights('food_model_2.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "\n",
    "\n",
    "model.save('food_model_best.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4   Use the best model to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model.load_weights('food_model_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the food list (in alphabetical order)\n",
    "with open('??.txt', 'r') as f: # the .txt file which contains a list of food assigned to you\n",
    "    x = f.readlines()\n",
    "food_list =[]\n",
    "for item in x:\n",
    "    food_list.append(item.strip('\\n'))\n",
    "food_list = sorted(food_list) # food_list needs to be sorted alphabetically before feed into prediction() function\n",
    "print(food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some related functions for image process and model prediction\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "def image_process(img):\n",
    "    image = load_img(img, target_size =(img_size, img_size))\n",
    "    image_array = img_to_array(image)/255\n",
    "    return image_array\n",
    "\n",
    "import pandas as pd\n",
    "def prediction(model, img_array, items_l):\n",
    "    prob = model.predict(img_array.reshape(1,img_size,img_size,3))\n",
    "    pro_df = pd.DataFrame(prob, columns = items_l)\n",
    "    result = items_l[np.argmax(prob)]\n",
    "    return pro_df, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction for the image you downloaded from internet\n",
    "import matplotlib.pyplot as plt\n",
    "img = '??.jpeg' # the picture you downloaded from internet, which contains a type of food in your food list\n",
    "plt.imshow(plt.imread(img))\n",
    "plt.show()\n",
    "\n",
    "img_array = image_process(img)\n",
    "prob_df, result = prediction(model, img_array, food_list)\n",
    "print('The prediction is: ', result, '\\n\\n', prob_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Assignment_1.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quDsfwn_IOru",
        "colab_type": "text"
      },
      "source": [
        "<table class=\"table table-bordered\">\n",
        "    <tr>\n",
        "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
        "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Assignment 1 - Food Classification Model (Individual)</h2><h3>AY2020/21 Semester</h3></th>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJHD7kqEIOrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "07960351-2588-4d3b-f7e5-77824374fab5"
      },
      "source": [
        "# Import the Required Packages\n",
        "\n",
        "from tensorflow import keras\n",
        "print('keras: ', keras.__version__)\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
        "\n",
        "import os, shutil"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras:  2.3.0-tf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:95% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wpbksIcISYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "471a1b30-acbc-4e77-9cc7-6f44c836dca0"
      },
      "source": [
        "!git clone \"https://github.com/JasonZev/DL-Assignment-master.git\"\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DL-Assignment-master'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 10044 (delta 0), reused 2 (delta 0), pack-reused 10041\u001b[K\n",
            "Receiving objects: 100% (10044/10044), 477.34 MiB | 15.20 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Checking out files: 100% (10004/10004), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdbAPkbUIOr3",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozQKNws9IOr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directories for your training, validation and test splits\n",
        "train_dir = '/content/DL-Assignment-master/train'\n",
        "validation_dir = '/content/DL-Assignment-master/validation'\n",
        "test_dir = '/content/DL-Assignment-master/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlZvtR_pIOr9",
        "colab_type": "text"
      },
      "source": [
        "## Step 2:  Develop the Image Classification Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9jEobE2IOr-",
        "colab_type": "text"
      },
      "source": [
        "### Model #1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9g9GJ81SIOr-",
        "colab_type": "code",
        "colab": {},
        "outputId": "e53c32ba-72fd-441f-8cb3-9cc000940364"
      },
      "source": [
        "# Build the Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "#Set image size as 150*150.\n",
        "img_size = 150\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(img_size, img_size, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "#model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "     zoom_range=0.2,\n",
        "     horizontal_flip=True,\n",
        "     fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 50x50\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=15,\n",
        "        class_mode='categorical')\n",
        "\n",
        "#test_generator = test_datagen.flow_from_directory(\n",
        "#        test_food_dir,\n",
        "#        target_size=(img_size, img_size),\n",
        "#        batch_size=10,\n",
        "#        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=16,\n",
        "        class_mode='categorical')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 48, 48, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 22, 22, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 9, 9, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 2, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 312,010\n",
            "Trainable params: 312,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Found 7500 images belonging to 10 classes.\n",
            "Found 2000 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5Q1_Wdq9IOsD",
        "colab_type": "code",
        "colab": {},
        "outputId": "f16a6241-6c80-4a37-d22d-c58f7ab026a9"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=500, # batch: 10 * 75 = 750 training images\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=125) # 10 * 20 = 200 = 200 validation images\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 150 steps, validate for 100 steps\n",
            "Epoch 1/30\n",
            "150/150 [==============================] - 103s 686ms/step - loss: 2.1652 - acc: 0.2083 - val_loss: 1.9008 - val_acc: 0.3240\n",
            "Epoch 2/30\n",
            "150/150 [==============================] - 97s 647ms/step - loss: 1.9216 - acc: 0.3267 - val_loss: 1.7711 - val_acc: 0.3845\n",
            "Epoch 3/30\n",
            "150/150 [==============================] - 97s 645ms/step - loss: 1.7964 - acc: 0.3796 - val_loss: 1.7607 - val_acc: 0.4015\n",
            "Epoch 4/30\n",
            "150/150 [==============================] - 101s 672ms/step - loss: 1.6898 - acc: 0.4223 - val_loss: 1.6919 - val_acc: 0.4290\n",
            "Epoch 5/30\n",
            "150/150 [==============================] - 103s 689ms/step - loss: 1.5822 - acc: 0.4643 - val_loss: 1.6785 - val_acc: 0.4245\n",
            "Epoch 6/30\n",
            "150/150 [==============================] - 103s 688ms/step - loss: 1.4811 - acc: 0.4977 - val_loss: 1.4606 - val_acc: 0.5035\n",
            "Epoch 7/30\n",
            "150/150 [==============================] - 108s 722ms/step - loss: 1.3822 - acc: 0.5359 - val_loss: 1.4225 - val_acc: 0.5235\n",
            "Epoch 8/30\n",
            "150/150 [==============================] - 107s 715ms/step - loss: 1.2926 - acc: 0.5641 - val_loss: 1.4235 - val_acc: 0.5215\n",
            "Epoch 9/30\n",
            "150/150 [==============================] - 103s 684ms/step - loss: 1.1918 - acc: 0.5968 - val_loss: 1.3823 - val_acc: 0.5440\n",
            "Epoch 10/30\n",
            "150/150 [==============================] - 101s 671ms/step - loss: 1.1006 - acc: 0.6303 - val_loss: 1.3971 - val_acc: 0.5335\n",
            "Epoch 11/30\n",
            "150/150 [==============================] - 97s 644ms/step - loss: 1.0119 - acc: 0.6591 - val_loss: 1.4509 - val_acc: 0.5440\n",
            "Epoch 12/30\n",
            "150/150 [==============================] - 101s 674ms/step - loss: 0.9139 - acc: 0.6899 - val_loss: 1.5618 - val_acc: 0.5235\n",
            "Epoch 13/30\n",
            "150/150 [==============================] - 104s 692ms/step - loss: 0.8178 - acc: 0.7208 - val_loss: 1.5263 - val_acc: 0.5540\n",
            "Epoch 14/30\n",
            "150/150 [==============================] - 86s 576ms/step - loss: 0.7217 - acc: 0.7499 - val_loss: 1.5822 - val_acc: 0.5460\n",
            "Epoch 15/30\n",
            "150/150 [==============================] - 73s 483ms/step - loss: 0.6389 - acc: 0.7859 - val_loss: 1.6018 - val_acc: 0.5745\n",
            "Epoch 16/30\n",
            "150/150 [==============================] - 75s 502ms/step - loss: 0.5370 - acc: 0.8184 - val_loss: 1.6868 - val_acc: 0.5495\n",
            "Epoch 17/30\n",
            "150/150 [==============================] - 75s 500ms/step - loss: 0.4583 - acc: 0.8443 - val_loss: 1.8871 - val_acc: 0.5310\n",
            "Epoch 18/30\n",
            "150/150 [==============================] - 73s 488ms/step - loss: 0.3979 - acc: 0.8684 - val_loss: 1.9514 - val_acc: 0.5580\n",
            "Epoch 19/30\n",
            "150/150 [==============================] - 77s 512ms/step - loss: 0.3482 - acc: 0.8841 - val_loss: 2.1567 - val_acc: 0.5325\n",
            "Epoch 20/30\n",
            "150/150 [==============================] - 75s 499ms/step - loss: 0.2987 - acc: 0.8992 - val_loss: 2.2800 - val_acc: 0.5535\n",
            "Epoch 21/30\n",
            "150/150 [==============================] - 81s 540ms/step - loss: 0.2439 - acc: 0.9201 - val_loss: 2.5468 - val_acc: 0.5295\n",
            "Epoch 22/30\n",
            "150/150 [==============================] - 78s 517ms/step - loss: 0.2359 - acc: 0.9195 - val_loss: 2.6859 - val_acc: 0.5300\n",
            "Epoch 23/30\n",
            "150/150 [==============================] - 88s 586ms/step - loss: 0.1935 - acc: 0.9351 - val_loss: 2.7086 - val_acc: 0.5480\n",
            "Epoch 24/30\n",
            "150/150 [==============================] - 93s 619ms/step - loss: 0.1748 - acc: 0.9413 - val_loss: 2.7565 - val_acc: 0.5400\n",
            "Epoch 25/30\n",
            "150/150 [==============================] - 96s 642ms/step - loss: 0.1671 - acc: 0.9435 - val_loss: 3.0703 - val_acc: 0.5305\n",
            "Epoch 26/30\n",
            "150/150 [==============================] - 90s 599ms/step - loss: 0.1580 - acc: 0.9496 - val_loss: 3.1312 - val_acc: 0.5420\n",
            "Epoch 27/30\n",
            "140/150 [===========================>..] - ETA: 5s - loss: 0.1367 - acc: 0.9563"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-16-59775ad27c28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m       validation_steps=100) # 10 * 20 = 200 = 200 validation images\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01XL1sWcIOsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the Training and Validation Accuracy & Loss Scores\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs0BY1qyIOsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the Model\n",
        "model.save('food_model_1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTxWztPDIOsR",
        "colab_type": "text"
      },
      "source": [
        "### Model #2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJV0_4V0IOsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f30d8b4-6187-4704-94bb-da9966059ecc"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50, VGG16, VGG19, InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "img_size = 150\n",
        "\n",
        "conv_base = ResNet50(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(img_size, img_size, 3))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base) #InceptionV3 pretrained\n",
        "#model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "#model.add(layers.Dense(256, activation='relu'))\n",
        "#model.add(layers.Dense(512, activation='relu'))\n",
        "#model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "conv_base.trainable = True\n",
        "\n",
        "#set_trainable = False\n",
        "#for layer in conv_base.layers:\n",
        "#    if layer.name == 'Input_':\n",
        "#        set_trainable = True # after black5_conv1, set_trainable becomes True\n",
        "#    if set_trainable:\n",
        "#       layer.trainable = True\n",
        "#    else:\n",
        "#        layer.trainable = False\n",
        "\n",
        "model.summary()\n",
        "conv_base.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=15,\n",
        "        class_mode='categorical')\n",
        "\n",
        "#test_generator = test_datagen.flow_from_directory(\n",
        "#        test_food_dir,\n",
        "#        target_size=(img_size, img_size),\n",
        "#        batch_size=10,\n",
        "#        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=15,\n",
        "        class_mode='categorical')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 5, 5, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 36,697,738\n",
            "Trainable params: 36,644,618\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 75, 75, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 75, 75, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 38, 38, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 38, 38, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 38, 38, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 38, 38, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 38, 38, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 38, 38, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 38, 38, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 38, 38, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 38, 38, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 38, 38, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 38, 38, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 38, 38, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 38, 38, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 38, 38, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 38, 38, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 38, 38, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 38, 38, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 38, 38, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 38, 38, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 19, 19, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 19, 19, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 19, 19, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 19, 19, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 19, 19, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 19, 19, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 19, 19, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 19, 19, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 19, 19, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 19, 19, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 19, 19, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 19, 19, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 19, 19, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 19, 19, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 19, 19, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 19, 19, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 19, 19, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 19, 19, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 19, 19, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 19, 19, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 19, 19, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 10, 10, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 10, 10, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 10, 10, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 10, 10, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 10, 10, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 10, 10, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 10, 10, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 10, 10, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 10, 10, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 10, 10, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 10, 10, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 10, 10, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 10, 10, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 10, 10, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 10, 10, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 10, 10, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 10, 10, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 10, 10, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 10, 10, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 10, 10, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 10, 10, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 10, 10, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 10, 10, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 10, 10, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 10, 10, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 10, 10, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 5, 5, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 5, 5, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 5, 5, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 5, 5, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 5, 5, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 5, 5, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 5, 5, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 5, 5, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 5, 5, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 5, 5, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 5, 5, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 5, 5, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 5, 5, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 5, 5, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 5, 5, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 5, 5, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "Found 7500 images belonging to 10 classes.\n",
            "Found 2000 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Uaz-wlYhIOsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "ad130590-a572-4c4f-8411-bf4ebe92ee69"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=375, # batch: 10 * 75 = 750 training images\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=100) # 10 * 20 = 200 = 200 validation images\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "375/375 [==============================] - 143s 382ms/step - loss: 2.4559 - acc: 0.2841 - val_loss: 3.6996 - val_acc: 0.1065\n",
            "Epoch 2/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 1.5193 - acc: 0.5107 - val_loss: 1.9546 - val_acc: 0.4060\n",
            "Epoch 3/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 1.2461 - acc: 0.6153 - val_loss: 0.8138 - val_acc: 0.7400\n",
            "Epoch 4/30\n",
            "375/375 [==============================] - 142s 378ms/step - loss: 1.1076 - acc: 0.6599 - val_loss: 0.7268 - val_acc: 0.7740\n",
            "Epoch 5/30\n",
            "375/375 [==============================] - 142s 378ms/step - loss: 0.9667 - acc: 0.7025 - val_loss: 0.7039 - val_acc: 0.7940\n",
            "Epoch 6/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.8984 - acc: 0.7213 - val_loss: 0.6535 - val_acc: 0.8115\n",
            "Epoch 7/30\n",
            "375/375 [==============================] - 142s 378ms/step - loss: 0.8217 - acc: 0.7540 - val_loss: 0.6347 - val_acc: 0.8205\n",
            "Epoch 8/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.7808 - acc: 0.7640 - val_loss: 0.6285 - val_acc: 0.8320\n",
            "Epoch 9/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.7231 - acc: 0.7811 - val_loss: 0.6304 - val_acc: 0.8335\n",
            "Epoch 10/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.6792 - acc: 0.7960 - val_loss: 0.6400 - val_acc: 0.8400\n",
            "Epoch 11/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.6590 - acc: 0.7991 - val_loss: 0.6364 - val_acc: 0.8370\n",
            "Epoch 12/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.6244 - acc: 0.8123 - val_loss: 0.6140 - val_acc: 0.8510\n",
            "Epoch 13/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.5966 - acc: 0.8168 - val_loss: 0.6621 - val_acc: 0.8490\n",
            "Epoch 14/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.5713 - acc: 0.8311 - val_loss: 0.6562 - val_acc: 0.8555\n",
            "Epoch 15/30\n",
            "375/375 [==============================] - 143s 380ms/step - loss: 0.5349 - acc: 0.8367 - val_loss: 0.6680 - val_acc: 0.8625\n",
            "Epoch 16/30\n",
            "375/375 [==============================] - 143s 380ms/step - loss: 0.5287 - acc: 0.8460 - val_loss: 0.6941 - val_acc: 0.8560\n",
            "Epoch 17/30\n",
            "375/375 [==============================] - 143s 381ms/step - loss: 0.4794 - acc: 0.8525 - val_loss: 0.7317 - val_acc: 0.8600\n",
            "Epoch 18/30\n",
            "375/375 [==============================] - 143s 381ms/step - loss: 0.4834 - acc: 0.8560 - val_loss: 0.7170 - val_acc: 0.8640\n",
            "Epoch 19/30\n",
            "375/375 [==============================] - 142s 380ms/step - loss: 0.4694 - acc: 0.8575 - val_loss: 0.7682 - val_acc: 0.8560\n",
            "Epoch 20/30\n",
            "375/375 [==============================] - 142s 380ms/step - loss: 0.4464 - acc: 0.8695 - val_loss: 0.8255 - val_acc: 0.8600\n",
            "Epoch 21/30\n",
            "375/375 [==============================] - 142s 380ms/step - loss: 0.4398 - acc: 0.8724 - val_loss: 0.7664 - val_acc: 0.8625\n",
            "Epoch 22/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.4006 - acc: 0.8768 - val_loss: 0.9016 - val_acc: 0.8560\n",
            "Epoch 23/30\n",
            "375/375 [==============================] - 142s 378ms/step - loss: 0.4114 - acc: 0.8844 - val_loss: 0.9016 - val_acc: 0.8635\n",
            "Epoch 24/30\n",
            "375/375 [==============================] - 142s 378ms/step - loss: 0.3932 - acc: 0.8849 - val_loss: 0.8782 - val_acc: 0.8625\n",
            "Epoch 25/30\n",
            "375/375 [==============================] - 142s 378ms/step - loss: 0.3862 - acc: 0.8868 - val_loss: 0.9168 - val_acc: 0.8645\n",
            "Epoch 26/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.3733 - acc: 0.8916 - val_loss: 0.9639 - val_acc: 0.8615\n",
            "Epoch 27/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.3601 - acc: 0.8955 - val_loss: 0.9853 - val_acc: 0.8680\n",
            "Epoch 28/30\n",
            "375/375 [==============================] - 142s 379ms/step - loss: 0.3587 - acc: 0.8996 - val_loss: 1.0578 - val_acc: 0.8705\n",
            "Epoch 29/30\n",
            "375/375 [==============================] - 142s 378ms/step - loss: 0.3369 - acc: 0.8977 - val_loss: 1.0346 - val_acc: 0.8645\n",
            "Epoch 30/30\n",
            "375/375 [==============================] - 142s 378ms/step - loss: 0.3397 - acc: 0.9004 - val_loss: 1.1185 - val_acc: 0.8655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS6jlhWzIOse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "1ac44329-99e9-4ed0-c2d4-ba618d31e408"
      },
      "source": [
        "# Plot the Training and Validation Accuracy & Loss Scores\n",
        "# Plot the Training and Validation Accuracy & Loss Scores\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqe6uKQyIOsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the Model\n",
        "model.save('food_model_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a7slhNmIOsm",
        "colab_type": "text"
      },
      "source": [
        "## Step 3  Evaluate the Developed Models using Testing Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-4f_YaQIOsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model #1\n",
        "model.load_weights('food_model_1.h5')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GRcxzbuIOsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model #2\n",
        "model.load_weights('food_model_2.h5')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiSFSvsfIOsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the best model\n",
        "\n",
        "\n",
        "model.save('food_model_best.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFU_IyYGIOsz",
        "colab_type": "text"
      },
      "source": [
        "## Step 4   Use the best model to make prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKOctKwHIOs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the model\n",
        "model.load_weights('food_model_best.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG1A8Pw7IOs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the food list (in alphabetical order)\n",
        "with open('??.txt', 'r') as f: # the .txt file which contains a list of food assigned to you\n",
        "    x = f.readlines()\n",
        "food_list =[]\n",
        "for item in x:\n",
        "    food_list.append(item.strip('\\n'))\n",
        "food_list = sorted(food_list) # food_list needs to be sorted alphabetically before feed into prediction() function\n",
        "print(food_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9-CmUpPIOs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define some related functions for image process and model prediction\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "def image_process(img):\n",
        "    image = load_img(img, target_size =(img_size, img_size))\n",
        "    image_array = img_to_array(image)/255\n",
        "    return image_array\n",
        "\n",
        "import pandas as pd\n",
        "def prediction(model, img_array, items_l):\n",
        "    prob = model.predict(img_array.reshape(1,img_size,img_size,3))\n",
        "    pro_df = pd.DataFrame(prob, columns = items_l)\n",
        "    result = items_l[np.argmax(prob)]\n",
        "    return pro_df, result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYsMBuHqIOtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make prediction for the image you downloaded from internet\n",
        "import matplotlib.pyplot as plt\n",
        "img = '??.jpeg' # the picture you downloaded from internet, which contains a type of food in your food list\n",
        "plt.imshow(plt.imread(img))\n",
        "plt.show()\n",
        "\n",
        "img_array = image_process(img)\n",
        "prob_df, result = prediction(model, img_array, food_list)\n",
        "print('The prediction is: ', result, '\\n\\n', prob_df)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}